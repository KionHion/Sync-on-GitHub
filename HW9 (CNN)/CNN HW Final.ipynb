{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpIFyPAIX4n0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ad787f0-883c-4731-a86a-2efda7d2119f"
      },
      "source": [
        "%env KERAS_BACKEND=tensorflow"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: KERAS_BACKEND=tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWeUCxj2X-zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test)=mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_test=x_test.reshape(10000,28,28,1)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)\n",
        "\n",
        "#最好做normalization，不然你的CNN會很漂\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2m3YJvOZUZQ",
        "colab_type": "text"
      },
      "source": [
        "##第一個設計\n",
        "##Constructing CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9XH9Hu4H5jQ",
        "colab_type": "code",
        "outputId": "004c9d4d-3f9b-4eab-8d2b-c8fd115626b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(4,(5,5,),padding='same', input_shape=(28,28,1)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(8,(5,5,),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(16,(5,5,),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten()) #把所有的Matrix合起來然後拉平，like ravel\n",
        "model.add(Dense(9))  #Fully connected的神經元\n",
        "model.add(Activation('relu'))\n",
        "#輸出的時候：\n",
        "model.add(Dense(10)) \n",
        "\n",
        "model.add(Activation('softmax')) #加起來自動要等於一\n",
        "\n",
        "model.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 28, 28, 4)         104       \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 28, 28, 4)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 14, 14, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 14, 14, 8)         808       \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 7, 7, 16)          3216      \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 9)                 1305      \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 10)                100       \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 5,533\n",
            "Trainable params: 5,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gamQOw6fZ9C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit(x_train, y_train, batch_size=50, epochs=50)   #0.9832\n",
        "#model.fit(x_train, y_train, batch_size=50, epochs=30)   #0.9791"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5wV5vKFu8n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1797
        },
        "outputId": "753067fe-9a9f-402a-810e-251bb0508dbb"
      },
      "source": [
        "#model.fit(x_train, y_train, batch_size=50, epochs=48, verbose=1, validation_data=(x_test, y_test)) #0.9840\n",
        "#model.fit(x_train, y_train, batch_size=40, epochs=50)    #0.9880\n",
        "model.fit(x_train, y_train, batch_size=50, epochs=48, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/48\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0899 - acc: 0.1544 - val_loss: 0.0898 - val_acc: 0.1812\n",
            "Epoch 2/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0896 - acc: 0.1865 - val_loss: 0.0893 - val_acc: 0.1975\n",
            "Epoch 3/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0884 - acc: 0.2058 - val_loss: 0.0868 - val_acc: 0.2550\n",
            "Epoch 4/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0772 - acc: 0.3957 - val_loss: 0.0519 - val_acc: 0.6612\n",
            "Epoch 5/48\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0291 - acc: 0.8098 - val_loss: 0.0165 - val_acc: 0.8939\n",
            "Epoch 6/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0143 - acc: 0.9066 - val_loss: 0.0112 - val_acc: 0.9258\n",
            "Epoch 7/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0108 - acc: 0.9293 - val_loss: 0.0087 - val_acc: 0.9439\n",
            "Epoch 8/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0090 - acc: 0.9403 - val_loss: 0.0080 - val_acc: 0.9482\n",
            "Epoch 9/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0078 - acc: 0.9491 - val_loss: 0.0069 - val_acc: 0.9553\n",
            "Epoch 10/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0070 - acc: 0.9544 - val_loss: 0.0060 - val_acc: 0.9611\n",
            "Epoch 11/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0065 - acc: 0.9581 - val_loss: 0.0063 - val_acc: 0.9580\n",
            "Epoch 12/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0060 - acc: 0.9610 - val_loss: 0.0051 - val_acc: 0.9661\n",
            "Epoch 13/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0056 - acc: 0.9638 - val_loss: 0.0048 - val_acc: 0.9678\n",
            "Epoch 14/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0052 - acc: 0.9660 - val_loss: 0.0044 - val_acc: 0.9729\n",
            "Epoch 15/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0049 - acc: 0.9685 - val_loss: 0.0043 - val_acc: 0.9734\n",
            "Epoch 16/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0047 - acc: 0.9698 - val_loss: 0.0042 - val_acc: 0.9726\n",
            "Epoch 17/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0045 - acc: 0.9715 - val_loss: 0.0041 - val_acc: 0.9728\n",
            "Epoch 18/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0043 - acc: 0.9725 - val_loss: 0.0037 - val_acc: 0.9761\n",
            "Epoch 19/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0042 - acc: 0.9731 - val_loss: 0.0042 - val_acc: 0.9719\n",
            "Epoch 20/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0040 - acc: 0.9743 - val_loss: 0.0037 - val_acc: 0.9768\n",
            "Epoch 21/48\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0039 - acc: 0.9754 - val_loss: 0.0038 - val_acc: 0.9766\n",
            "Epoch 22/48\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0037 - acc: 0.9762 - val_loss: 0.0037 - val_acc: 0.9756\n",
            "Epoch 23/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0037 - acc: 0.9767 - val_loss: 0.0034 - val_acc: 0.9792\n",
            "Epoch 24/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0035 - acc: 0.9778 - val_loss: 0.0034 - val_acc: 0.9773\n",
            "Epoch 25/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0034 - acc: 0.9780 - val_loss: 0.0035 - val_acc: 0.9777\n",
            "Epoch 26/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0033 - acc: 0.9792 - val_loss: 0.0033 - val_acc: 0.9791\n",
            "Epoch 27/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0033 - acc: 0.9795 - val_loss: 0.0035 - val_acc: 0.9779\n",
            "Epoch 28/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0032 - acc: 0.9797 - val_loss: 0.0034 - val_acc: 0.9789\n",
            "Epoch 29/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0031 - acc: 0.9805 - val_loss: 0.0029 - val_acc: 0.9812\n",
            "Epoch 30/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0030 - acc: 0.9808 - val_loss: 0.0029 - val_acc: 0.9817\n",
            "Epoch 31/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0029 - acc: 0.9818 - val_loss: 0.0031 - val_acc: 0.9814\n",
            "Epoch 32/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0029 - acc: 0.9818 - val_loss: 0.0028 - val_acc: 0.9820\n",
            "Epoch 33/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0029 - acc: 0.9820 - val_loss: 0.0030 - val_acc: 0.9819\n",
            "Epoch 34/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0028 - acc: 0.9830 - val_loss: 0.0031 - val_acc: 0.9804\n",
            "Epoch 35/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0027 - acc: 0.9833 - val_loss: 0.0028 - val_acc: 0.9821\n",
            "Epoch 36/48\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0027 - acc: 0.9836 - val_loss: 0.0029 - val_acc: 0.9814\n",
            "Epoch 37/48\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0026 - acc: 0.9839 - val_loss: 0.0028 - val_acc: 0.9827\n",
            "Epoch 38/48\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0026 - acc: 0.9842 - val_loss: 0.0029 - val_acc: 0.9827\n",
            "Epoch 39/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0025 - acc: 0.9844 - val_loss: 0.0026 - val_acc: 0.9826\n",
            "Epoch 40/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0025 - acc: 0.9849 - val_loss: 0.0026 - val_acc: 0.9834\n",
            "Epoch 41/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0024 - acc: 0.9851 - val_loss: 0.0027 - val_acc: 0.9832\n",
            "Epoch 42/48\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0024 - acc: 0.9850 - val_loss: 0.0025 - val_acc: 0.9839\n",
            "Epoch 43/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0024 - acc: 0.9856 - val_loss: 0.0026 - val_acc: 0.9830\n",
            "Epoch 44/48\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0023 - acc: 0.9859 - val_loss: 0.0027 - val_acc: 0.9830\n",
            "Epoch 45/48\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0023 - acc: 0.9864 - val_loss: 0.0024 - val_acc: 0.9844\n",
            "Epoch 46/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0022 - acc: 0.9863 - val_loss: 0.0025 - val_acc: 0.9840\n",
            "Epoch 47/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0022 - acc: 0.9872 - val_loss: 0.0025 - val_acc: 0.9834\n",
            "Epoch 48/48\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0022 - acc: 0.9868 - val_loss: 0.0027 - val_acc: 0.9831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee6d09e978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6vazWfvt5dc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "45afc10d-ce1f-4243-e2a3-57ecd4763fd8"
      },
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 57us/step\n",
            "loss: 0.002652009207928944\n",
            "正確率 0.9831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMR_sCnV4hDM",
        "colab_type": "text"
      },
      "source": [
        "##第二個設計\n",
        "\n",
        "這次就故意把filter設計成越來越少，看看後果是什麼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t65Xj0nj4kfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "a67338b2-849f-418b-9161-85068bcca31a"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "model_1.add(Conv2D(16,(5,5,),padding='same', input_shape=(28,28,1)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "model_1.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model_1.add(Conv2D(8,(5,5,),padding='same'))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "model_1.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model_1.add(Conv2D(4,(5,5,),padding='same'))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "model_1.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model_1.add(Flatten()) #把所有的Matrix合起來然後拉平，like ravel\n",
        "model_1.add(Dense(9))  #Fully connected的神經元\n",
        "model_1.add(Activation('relu'))\n",
        "#輸出的時候：\n",
        "model_1.add(Dense(10)) \n",
        "\n",
        "model_1.add(Activation('softmax')) #加起來自動要等於一\n",
        "\n",
        "model_1.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 28, 28, 16)        416       \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 14, 14, 8)         3208      \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 7, 7, 4)           804       \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 7, 7, 4)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 3, 3, 4)           0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 9)                 333       \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 10)                100       \n",
            "_________________________________________________________________\n",
            "activation_70 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 4,861\n",
            "Trainable params: 4,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWp9EVMd5tig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1797
        },
        "outputId": "65b40cdc-05b5-47ce-e9d7-67920d32e6d0"
      },
      "source": [
        "model_1.fit(x_train, y_train, batch_size=50, epochs=48, verbose=1, validation_data=(x_test, y_test)) #0.9758"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/48\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0896 - acc: 0.1309 - val_loss: 0.0890 - val_acc: 0.1485\n",
            "Epoch 2/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0864 - acc: 0.2215 - val_loss: 0.0787 - val_acc: 0.3861\n",
            "Epoch 3/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0569 - acc: 0.5864 - val_loss: 0.0370 - val_acc: 0.7538\n",
            "Epoch 4/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0335 - acc: 0.7721 - val_loss: 0.0293 - val_acc: 0.7993\n",
            "Epoch 5/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0286 - acc: 0.8048 - val_loss: 0.0258 - val_acc: 0.8233\n",
            "Epoch 6/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0261 - acc: 0.8218 - val_loss: 0.0258 - val_acc: 0.8261\n",
            "Epoch 7/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0240 - acc: 0.8334 - val_loss: 0.0202 - val_acc: 0.8513\n",
            "Epoch 8/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0189 - acc: 0.8716 - val_loss: 0.0145 - val_acc: 0.9056\n",
            "Epoch 9/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0155 - acc: 0.8973 - val_loss: 0.0138 - val_acc: 0.9095\n",
            "Epoch 10/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0135 - acc: 0.9122 - val_loss: 0.0114 - val_acc: 0.9236\n",
            "Epoch 11/48\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0120 - acc: 0.9217 - val_loss: 0.0095 - val_acc: 0.9388\n",
            "Epoch 12/48\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0108 - acc: 0.9299 - val_loss: 0.0086 - val_acc: 0.9438\n",
            "Epoch 13/48\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0100 - acc: 0.9352 - val_loss: 0.0082 - val_acc: 0.9472\n",
            "Epoch 14/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0093 - acc: 0.9387 - val_loss: 0.0084 - val_acc: 0.9444\n",
            "Epoch 15/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0088 - acc: 0.9424 - val_loss: 0.0104 - val_acc: 0.9327\n",
            "Epoch 16/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0085 - acc: 0.9447 - val_loss: 0.0070 - val_acc: 0.9544\n",
            "Epoch 17/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0081 - acc: 0.9470 - val_loss: 0.0070 - val_acc: 0.9545\n",
            "Epoch 18/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0078 - acc: 0.9492 - val_loss: 0.0071 - val_acc: 0.9535\n",
            "Epoch 19/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0075 - acc: 0.9515 - val_loss: 0.0068 - val_acc: 0.9531\n",
            "Epoch 20/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0073 - acc: 0.9520 - val_loss: 0.0068 - val_acc: 0.9554\n",
            "Epoch 21/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0071 - acc: 0.9535 - val_loss: 0.0065 - val_acc: 0.9588\n",
            "Epoch 22/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0069 - acc: 0.9549 - val_loss: 0.0060 - val_acc: 0.9605\n",
            "Epoch 23/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0068 - acc: 0.9567 - val_loss: 0.0058 - val_acc: 0.9617\n",
            "Epoch 24/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0066 - acc: 0.9579 - val_loss: 0.0060 - val_acc: 0.9607\n",
            "Epoch 25/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0064 - acc: 0.9585 - val_loss: 0.0058 - val_acc: 0.9627\n",
            "Epoch 26/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0063 - acc: 0.9591 - val_loss: 0.0058 - val_acc: 0.9614\n",
            "Epoch 27/48\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0061 - acc: 0.9607 - val_loss: 0.0057 - val_acc: 0.9643\n",
            "Epoch 28/48\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0060 - acc: 0.9610 - val_loss: 0.0055 - val_acc: 0.9638\n",
            "Epoch 29/48\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0058 - acc: 0.9629 - val_loss: 0.0053 - val_acc: 0.9666\n",
            "Epoch 30/48\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0058 - acc: 0.9628 - val_loss: 0.0053 - val_acc: 0.9642\n",
            "Epoch 31/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0056 - acc: 0.9637 - val_loss: 0.0051 - val_acc: 0.9670\n",
            "Epoch 32/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0055 - acc: 0.9648 - val_loss: 0.0055 - val_acc: 0.9658\n",
            "Epoch 33/48\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0054 - acc: 0.9655 - val_loss: 0.0053 - val_acc: 0.9659\n",
            "Epoch 34/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0053 - acc: 0.9660 - val_loss: 0.0051 - val_acc: 0.9678\n",
            "Epoch 35/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0052 - acc: 0.9667 - val_loss: 0.0049 - val_acc: 0.9690\n",
            "Epoch 36/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0051 - acc: 0.9676 - val_loss: 0.0046 - val_acc: 0.9694\n",
            "Epoch 37/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0050 - acc: 0.9673 - val_loss: 0.0047 - val_acc: 0.9697\n",
            "Epoch 38/48\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0049 - acc: 0.9686 - val_loss: 0.0050 - val_acc: 0.9680\n",
            "Epoch 39/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0049 - acc: 0.9691 - val_loss: 0.0047 - val_acc: 0.9701\n",
            "Epoch 40/48\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0048 - acc: 0.9698 - val_loss: 0.0046 - val_acc: 0.9707\n",
            "Epoch 41/48\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0047 - acc: 0.9701 - val_loss: 0.0044 - val_acc: 0.9715\n",
            "Epoch 42/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0047 - acc: 0.9703 - val_loss: 0.0047 - val_acc: 0.9691\n",
            "Epoch 43/48\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0046 - acc: 0.9712 - val_loss: 0.0046 - val_acc: 0.9696\n",
            "Epoch 44/48\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0045 - acc: 0.9714 - val_loss: 0.0044 - val_acc: 0.9718\n",
            "Epoch 45/48\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0044 - acc: 0.9720 - val_loss: 0.0047 - val_acc: 0.9700\n",
            "Epoch 46/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0044 - acc: 0.9724 - val_loss: 0.0044 - val_acc: 0.9707\n",
            "Epoch 47/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0043 - acc: 0.9727 - val_loss: 0.0042 - val_acc: 0.9728\n",
            "Epoch 48/48\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0043 - acc: 0.9725 - val_loss: 0.0042 - val_acc: 0.9733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee6cc786d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjj2HV645zJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "47a77cbb-97ea-4e5b-f7b5-2863bab7263f"
      },
      "source": [
        "score = model_1.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 56us/step\n",
            "loss: 0.004193800970243501\n",
            "正確率 0.9733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_NkYwKk8rEM",
        "colab_type": "text"
      },
      "source": [
        "##第三個設計\n",
        "就是不要做normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ1HDWcwBewY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train_1, y_train_1), (x_test_1, y_test_1)=mnist.load_data()\n",
        "\n",
        "x_train_1 = x_train_1.reshape(60000,28,28,1)\n",
        "x_test_1=x_test_1.reshape(10000,28,28,1)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "y_train_1 = np_utils.to_categorical(y_train_1,10)\n",
        "y_test_1 = np_utils.to_categorical(y_test_1,10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLlQzIzy8xBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "dca55481-cee7-440e-f653-c843aa7b2845"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "model_2 = Sequential()\n",
        "\n",
        "model_2.add(Conv2D(4,(5,5,),padding='same', input_shape=(28,28,1)))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "model_2.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model_2.add(Conv2D(8,(5,5,),padding='same'))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "model_2.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model_2.add(Conv2D(16,(5,5,),padding='same'))\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "model_2.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model_2.add(Flatten()) #把所有的Matrix合起來然後拉平，like ravel\n",
        "model_2.add(Dense(9))  #Fully connected的神經元\n",
        "model_2.add(Activation('relu'))\n",
        "#輸出的時候：\n",
        "model_2.add(Dense(10)) \n",
        "\n",
        "model_2.add(Activation('softmax')) #加起來自動要等於一\n",
        "\n",
        "model_2.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_43 (Conv2D)           (None, 28, 28, 4)         104       \n",
            "_________________________________________________________________\n",
            "activation_71 (Activation)   (None, 28, 28, 4)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 14, 14, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 14, 14, 8)         808       \n",
            "_________________________________________________________________\n",
            "activation_72 (Activation)   (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 7, 7, 16)          3216      \n",
            "_________________________________________________________________\n",
            "activation_73 (Activation)   (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 9)                 1305      \n",
            "_________________________________________________________________\n",
            "activation_74 (Activation)   (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                100       \n",
            "_________________________________________________________________\n",
            "activation_75 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 5,533\n",
            "Trainable params: 5,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcgsmf8TBmAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1797
        },
        "outputId": "aaf51fad-c7e7-4329-a1df-05dd5e498e7d"
      },
      "source": [
        "model_2.fit(x_train_1, y_train_1, batch_size=50, epochs=48, verbose=1, validation_data=(x_test_1, y_test_1)) #0.9758"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/48\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0769 - acc: 0.2899 - val_loss: 0.0640 - val_acc: 0.4016\n",
            "Epoch 2/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0582 - acc: 0.4910 - val_loss: 0.0502 - val_acc: 0.5642\n",
            "Epoch 3/48\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0499 - acc: 0.5682 - val_loss: 0.0493 - val_acc: 0.5735\n",
            "Epoch 4/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0480 - acc: 0.5766 - val_loss: 0.0468 - val_acc: 0.5813\n",
            "Epoch 5/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0469 - acc: 0.5830 - val_loss: 0.0460 - val_acc: 0.5853\n",
            "Epoch 6/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0449 - acc: 0.6052 - val_loss: 0.0395 - val_acc: 0.6661\n",
            "Epoch 7/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0376 - acc: 0.7065 - val_loss: 0.0346 - val_acc: 0.7268\n",
            "Epoch 8/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0318 - acc: 0.7628 - val_loss: 0.0284 - val_acc: 0.8049\n",
            "Epoch 9/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0282 - acc: 0.8175 - val_loss: 0.0236 - val_acc: 0.8521\n",
            "Epoch 10/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0148 - acc: 0.9118 - val_loss: 0.0099 - val_acc: 0.9389\n",
            "Epoch 11/48\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.0091 - acc: 0.9449 - val_loss: 0.0077 - val_acc: 0.9529\n",
            "Epoch 12/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0075 - acc: 0.9543 - val_loss: 0.0059 - val_acc: 0.9641\n",
            "Epoch 13/48\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0067 - acc: 0.9598 - val_loss: 0.0055 - val_acc: 0.9670\n",
            "Epoch 14/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0058 - acc: 0.9651 - val_loss: 0.0055 - val_acc: 0.9680\n",
            "Epoch 15/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0055 - acc: 0.9669 - val_loss: 0.0055 - val_acc: 0.9672\n",
            "Epoch 16/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0053 - acc: 0.9685 - val_loss: 0.0055 - val_acc: 0.9686\n",
            "Epoch 17/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0050 - acc: 0.9709 - val_loss: 0.0050 - val_acc: 0.9705\n",
            "Epoch 18/48\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.0047 - acc: 0.9725 - val_loss: 0.0047 - val_acc: 0.9722\n",
            "Epoch 19/48\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0046 - acc: 0.9731 - val_loss: 0.0044 - val_acc: 0.9742\n",
            "Epoch 20/48\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0045 - acc: 0.9736 - val_loss: 0.0046 - val_acc: 0.9730\n",
            "Epoch 21/48\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0041 - acc: 0.9759 - val_loss: 0.0047 - val_acc: 0.9723\n",
            "Epoch 22/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0039 - acc: 0.9769 - val_loss: 0.0039 - val_acc: 0.9778\n",
            "Epoch 23/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0038 - acc: 0.9772 - val_loss: 0.0074 - val_acc: 0.9571\n",
            "Epoch 24/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0039 - acc: 0.9771 - val_loss: 0.0043 - val_acc: 0.9748\n",
            "Epoch 25/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0035 - acc: 0.9794 - val_loss: 0.0043 - val_acc: 0.9749\n",
            "Epoch 26/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0033 - acc: 0.9804 - val_loss: 0.0042 - val_acc: 0.9761\n",
            "Epoch 27/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0033 - acc: 0.9805 - val_loss: 0.0037 - val_acc: 0.9787\n",
            "Epoch 28/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0033 - acc: 0.9809 - val_loss: 0.0043 - val_acc: 0.9747\n",
            "Epoch 29/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0033 - acc: 0.9810 - val_loss: 0.0041 - val_acc: 0.9762\n",
            "Epoch 30/48\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0032 - acc: 0.9812 - val_loss: 0.0038 - val_acc: 0.9781\n",
            "Epoch 31/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0031 - acc: 0.9820 - val_loss: 0.0036 - val_acc: 0.9790\n",
            "Epoch 32/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0030 - acc: 0.9827 - val_loss: 0.0038 - val_acc: 0.9781\n",
            "Epoch 33/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0029 - acc: 0.9832 - val_loss: 0.0043 - val_acc: 0.9743\n",
            "Epoch 34/48\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0028 - acc: 0.9834 - val_loss: 0.0040 - val_acc: 0.9764\n",
            "Epoch 35/48\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0028 - acc: 0.9836 - val_loss: 0.0038 - val_acc: 0.9786\n",
            "Epoch 36/48\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.0027 - acc: 0.9844 - val_loss: 0.0041 - val_acc: 0.9758\n",
            "Epoch 37/48\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0026 - acc: 0.9847 - val_loss: 0.0035 - val_acc: 0.9797\n",
            "Epoch 38/48\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0025 - acc: 0.9855 - val_loss: 0.0035 - val_acc: 0.9801\n",
            "Epoch 39/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0025 - acc: 0.9853 - val_loss: 0.0035 - val_acc: 0.9803\n",
            "Epoch 40/48\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0025 - acc: 0.9853 - val_loss: 0.0045 - val_acc: 0.9739\n",
            "Epoch 41/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0025 - acc: 0.9855 - val_loss: 0.0035 - val_acc: 0.9799\n",
            "Epoch 42/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0025 - acc: 0.9856 - val_loss: 0.0034 - val_acc: 0.9803\n",
            "Epoch 43/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0025 - acc: 0.9854 - val_loss: 0.0039 - val_acc: 0.9780\n",
            "Epoch 44/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0025 - acc: 0.9859 - val_loss: 0.0036 - val_acc: 0.9796\n",
            "Epoch 45/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0026 - acc: 0.9849 - val_loss: 0.0036 - val_acc: 0.9792\n",
            "Epoch 46/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0026 - acc: 0.9853 - val_loss: 0.0037 - val_acc: 0.9792\n",
            "Epoch 47/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0025 - acc: 0.9857 - val_loss: 0.0037 - val_acc: 0.9796\n",
            "Epoch 48/48\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0025 - acc: 0.9860 - val_loss: 0.0045 - val_acc: 0.9747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee6c97abe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5eBFC45Boqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6918ef17-48da-4a19-b3cc-b0888c0a0bb9"
      },
      "source": [
        "score = model_2.evaluate(x_test_1, y_test_1)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 59us/step\n",
            "loss: 0.004541242292661053\n",
            "正確率 0.9747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCGs5WtbDia8",
        "colab_type": "text"
      },
      "source": [
        "##結論：\n",
        "### 第一個CNN：只改了epoch和batch_size以提高正確率\n",
        "正確率：0.9831\n",
        "\n",
        "### 第二個CNN：把Filter設計成越來越少，16、8、4，其他保持一樣\n",
        "正確率：0.9733\n",
        "\n",
        "### 第三個CNN：不要normalization，其他保持一樣\n",
        "正確率：0.9747"
      ]
    }
  ]
}